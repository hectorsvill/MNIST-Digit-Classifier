# MNIST Digit Classifier - Local Project with API

This project provides a complete, locally runnable system for classifying handwritten digits using TensorFlow/Keras. It includes scripts to train a Convolutional Neural Network on the MNIST dataset, evaluate its performance, and serve the trained model via a Flask web API with prediction and basic learning endpoints. The code is structured modularly, features a pytest test suite, and is designed for easy setup and execution on your local machine.

Generation Note

The foundational code structure, API implementation, test suite, and documentation for this project were generated by an AI assistant (Gemini 2.5 Pro) based on detailed prompts. While reviewed and potentially modified, this serves as a starting point demonstrating AI-assisted development for ML projects.

## Setup Instructions

1.  **Clone or Download:** Get the project code onto your local machine.
    ```bash
    # If using git
    git clone <your-repository-url>
    cd mnist_local_project
    ```

2.  **Create Virtual Environment:** (Highly Recommended) This isolates project dependencies.
    ```bash
    python -m venv venv
    ```

3.  **Activate Virtual Environment:**
    *   **Windows (Command Prompt/PowerShell):**
        ```bash
        venv\Scripts\activate
        ```
    *   **macOS/Linux (bash/zsh):**
        ```bash
        source venv/bin/activate
        ```
    *(You should see `(venv)` at the start of your terminal prompt)*

4.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

## Usage

### 1. Training the Model

This script handles loading data, building the model, running the custom training loop, evaluating performance, and saving the trained model and plots.

*   **Run basic training (using defaults from `src/config.py`):**
    ```bash
    python train.py
    ```
    *Output:* You will see training progress per epoch, evaluation results (accuracy, loss, classification report), and messages indicating where the model (`.keras` file) and plots (`.png` files for history and confusion matrix) are saved (typically in the `models/` directory).

*   **Run training with custom parameters:**
    ```bash
    python train.py --epochs 5 --lr 0.0005 --batch_size 64 --save_path ./models/my_custom_model.keras
    ```
    *(Use `python train.py --help` to see all available options.)*

### 2. Running the API Server

This script loads the *trained* model (make sure you've run `train.py` first!) and starts the Flask web server.

*   **Start the development server:**
    ```bash
    python run_api.py
    ```
    *Output:* The server will start, usually listening on `http://127.0.0.1:5000`. Keep this terminal running to keep the API active.

*   **Start with Gunicorn (Recommended for better performance/stability):**
    *(First, ensure Gunicorn is installed: `pip install gunicorn`)*
    ```bash
    # Example: Run with 2 worker processes, accessible on your network
    gunicorn --workers 2 --bind 0.0.0.0:5000 run_api:app
    ```
    *(Note: `run_api:app` tells Gunicorn to look inside the `run_api.py` file for the Flask `app` object, which is created by our `create_app` factory.)*

### 3. Using the API

Once the API server is running, you can send HTTP requests to its endpoints.

#### API Endpoints Documentation

**A. Health Check**

*   **Endpoint:** `/health`
*   **Method:** `GET`
*   **Description:** Checks if the API is running and the model is loaded.
*   **Request Body:** None
*   **Success Response (200 OK):**
    ```json
    {
      "status": "ok",
      "message": "Model is loaded."
    }
    ```
*   **Error Response (503 Service Unavailable):** (If model failed to load)
    ```json
    {
      "status": "error",
      "message": "Model is not loaded!"
    }
    ```
*   **Example `curl`:**
    ```bash
    curl http://127.0.0.1:5000/health
    ```

**B. Predict Digit**

*   **Endpoint:** `/predict`
*   **Method:** `POST`
*   **Description:** Predicts the digit for a given flattened image array.
*   **Request Body:**
    ```json
    {
      "features": [ ... ] // List/array of 784 pixel values (float, 0.0-1.0 or 0-255)
    }
    ```
*   **Success Response (200 OK):**
    ```json
    {
      "prediction": 7,        // Predicted digit (int)
      "confidence": 0.9987    // Model's confidence score (float)
    }
    ```
*   **Error Response (400 Bad Request):** (If input is malformed)
    ```json
    {
      "error": "Missing 'features' key in JSON input"
      // or "Invalid input data: Expected 784 features..."
    }
    ```
*   **Example `curl`:** (Replace `[...]` with actual pixel values)
    ```bash
    curl -X POST http://127.0.0.1:5000/predict \
         -H "Content-Type: application/json" \
         -d '{"features": [0.0, 0.0, ..., 0.9, 0.2, ..., 0.0]}'
    ```

**C. Online Learning (Fine-tuning)**

*   **Endpoint:** `/learn`
*   **Method:** `POST`
*   **Description:** Updates the *in-memory* model using a single labeled example. Useful for very basic fine-tuning or correcting specific misclassifications. **Note:** These changes are lost when the API restarts unless you add model saving logic here.
*   **Request Body:**
    ```json
    {
      "features": [ ... ], // List/array of 784 pixel values (float, 0.0-1.0 or 0-255)
      "label": 3           // The correct digit label (int, 0-9)
    }
    ```
*   **Success Response (200 OK):**
    ```json
    {
      "message": "Model updated with the provided example.",
      "label_provided": 3,
      "loss_on_example": 0.0512, // Loss calculated for this single example
      "accuracy_on_example": 1.0 // Accuracy for this single example (usually 1.0 or 0.0)
    }
    ```
*   **Error Response (400 Bad Request):** (If input is malformed)
    ```json
    {
      "error": "Missing 'features' or 'label' key"
      // or "Invalid input data: Label must be an integer..."
    }
    ```
*   **Example `curl`:** (Replace `[...]` and label)
    ```bash
    curl -X POST http://127.0.0.1:5000/learn \
         -H "Content-Type: application/json" \
         -d '{"features": [0.0, ..., 1.0, ..., 0.0], "label": 3}'
    ```

## Running Tests

The project includes a test suite using `pytest` to verify the functionality of different components.

1.  **Ensure Dependencies:** Make sure you have installed requirements (`pytest`, `pytest-mock`, `requests` are included).
2.  **Run Tests:** From the project's root directory (`mnist_local_project/`):
    ```bash
    pytest
    ```
    *Output:* Pytest will discover and run tests in the `tests/` directory. You should see output indicating the number of tests passed (e.g., `== 17 passed in 0.XXs ==`).

## How the Code Works (Conceptual Overview)

This project follows a modular structure to separate different concerns:

*   **`src/config.py`**
    *   **What:** Central place for configuration variables.
    *   **Why:** Avoids hardcoding values like file paths, learning rates, epochs, etc., directly into the logic code. Makes it easy to change parameters.
    *   **How:** Defines Python constants that are imported by other modules.

*   **`src/data_loader.py`**
    *   **What:** Handles loading the MNIST dataset and preparing it for the model.
    *   **Why:** Isolates data acquisition and preprocessing logic from model definition and training. Makes it easier to swap datasets or change preprocessing steps later.
    *   **How:** Uses `tf.keras.datasets.mnist.load_data()`. Performs normalization (scaling pixel values to 0-1), flattening (converting 28x28 images to 784-element vectors), and one-hot encoding (converting integer labels like `5` to vectors like `[0,0,0,0,0,1,0,0,0,0]`). It also splits the data into training, validation, and test sets and provides a utility (`create_tf_dataset`) to wrap data in `tf.data.Dataset` objects for efficient batching during training.

*   **`src/model.py`**
    *   **What:** Defines the neural network architecture.
    *   **Why:** Separates the model's structure from the training and data handling code.
    *   **How:** Uses `tf.keras.models.Sequential` to define a simple Multi-Layer Perceptron (MLP) with Dense layers, ReLU activation, Dropout (for regularization), and a final Dense layer with Softmax activation (to output probabilities for each digit class).

*   **`src/training.py`**
    *   **What:** Implements the model training process, evaluation, and result visualization.
    *   **Why:** Encapsulates the core logic of teaching the model. Demonstrates a more explicit training approach compared to just using `model.fit()`.
    *   **How:**
        *   Defines `train_step` and `validation_step` functions decorated with `@tf.function` for performance.
        *   `train_step` uses `tf.GradientTape` to record operations, calculate the loss (Categorical Crossentropy), compute gradients (backpropagation), and apply updates using an optimizer (Adam).
        *   `run_training` orchestrates the main loop over epochs and batches, calling the step functions and tracking metrics (loss, accuracy).
        *   `evaluate_model` uses the trained model to predict on the unseen test set and calculates metrics like accuracy, generates a classification report (precision, recall, F1 per digit), and creates a confusion matrix.
        *   `plot_history` visualizes the training/validation loss and accuracy over epochs.
        *   Plots are saved to files (e.g., `training_history.png`, `confusion_matrix.png`) in the `models/` directory instead of being displayed interactively.

*   **`src/api/`** (`app.py`, `preprocessing.py`)
    *   **What:** Implements the Flask web API to serve the trained model.
    *   **Why:** Provides a standard interface for other applications or users to interact with the trained model over HTTP.
    *   **How:**
        *   `preprocessing.py`: Contains a function specifically designed to take raw input from the API request (like a list of numbers) and prepare it (normalize, clamp, reshape) for the model's `predict` or `train_on_batch` methods. It includes heuristics to handle inputs potentially scaled 0-255 or already 0-1.
        *   `app.py`: Uses the "Factory Pattern" (`create_app` function) to initialize the Flask app. It loads the saved Keras model (`.keras` file) on startup. It defines routes (`@app.route`) for `/health`, `/predict`, and `/learn`. These routes parse incoming JSON requests, use the API preprocessing function, call the appropriate model method (`model.predict`, `model.train_on_batch`), and return JSON responses. Includes basic error handling for invalid requests or model errors.

*   **`train.py` (Script)**
    *   **What:** Top-level script to orchestrate the training process.
    *   **Why:** Provides a simple command-line interface to start training.
    *   **How:** Imports functions/classes from the `src` modules. Parses command-line arguments (`argparse`). Calls data loading, model building, training, evaluation, and model saving functions in the correct order. Compiles the model before evaluation because `model.evaluate` requires it.

*   **`run_api.py` (Script)**
    *   **What:** Top-level script to launch the Flask API server.
    *   **Why:** Provides a clean way to start the API, separating server execution from the app definition. Necessary for running with WSGI servers like Gunicorn.
    *   **How:** Imports the `create_app` factory from `src.api.app`. Parses command-line arguments for host/port. Creates the app instance and runs it using `app.run()` (for development) or allows a WSGI server to run the `app` object.

*   **`tests/`**
    *   **What:** Automated tests for the project components.
    *   **Why:** Ensures code correctness, prevents regressions when making changes, and verifies component interactions.
    *   **How:** Uses `pytest`. `conftest.py` defines shared fixtures like a mock model and an API test client. Individual `test_*.py` files contain test functions that use these fixtures to assert expected behavior for data loading, model building, and API endpoints (including success and error cases).